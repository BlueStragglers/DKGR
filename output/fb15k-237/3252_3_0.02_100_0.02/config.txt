{'LSTM_layers': 1,
 'Lambda': 0.02,
 'base_output_dir': 'output/fb15k-237/',
 'batch_size': 256,
 'beta': 0.02,
 'create_vocab': 0,
 'data_input_dir': 'datasets/data_preprocessed/FB15K-237/',
 'decay_batch': 100,
 'decay_rate': 0.9,
 'embedding_size': 50,
 'eval_every': 4000,
 'gamma': 1,
 'grad_clip_norm': 5,
 'hidden_size': 50,
 'input_file': 'train.txt',
 'input_files': ['datasets/data_preprocessed/FB15K-237//train.txt'],
 'l2_reg_const': 0.01,
 'learning_rate': 0.0001,
 'load_model': False,
 'log_dir': './logs/',
 'log_file_name': 'output/fb15k-237//3252_3_0.02_100_0.02/log.txt',
 'max_num_actions': 100,
 'model_dir': 'output/fb15k-237//3252_3_0.02_100_0.02/model/',
 'model_load_dir': 'saved_models/fb15k-237',
 'negative_reward': 0,
 'nell_evaluation': 0,
 'num_rollouts': 20,
 'output_dir': 'output/fb15k-237//3252_3_0.02_100_0.02',
 'output_file': '',
 'path_length': 3,
 'path_logger_file': 'output/fb15k-237//3252_3_0.02_100_0.02',
 'pool': 'max',
 'positive_reward': 1.0,
 'reward_dir': 'output/fb15k-237//3252_3_0.02_100_0.02/reward.npy',
 'test_rollouts': 100,
 'total_iterations': 1000,
 'train_entity_embeddings': False,
 'train_relation_embeddings': True,
 'use_cluster_embeddings': 0,
 'use_cuda': 1,
 'use_entity_embeddings': False,
 'vocab_dir': 'datasets/data_preprocessed/FB15K-237/vocab'}
